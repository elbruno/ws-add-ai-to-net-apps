{
    "sk01_imports": {
        "prefix": "sk01_imports",
        "body": [
            "#pragma warning disable SKEXP0001",
            "#pragma warning disable SKEXP0010",
            "#pragma warning disable SKEXP0020",
            "#pragma warning disable SKEXP0027",
            "#pragma warning disable SKEXP0050",
            "",
            "using Microsoft.SemanticKernel.ChatCompletion;",
            "using Microsoft.SemanticKernel.Connectors.OpenAI;",
            ""
        ],
        "description": "add sk imports to aspnet program file"
    },
    "sk02_addAOAIChat": {
        "prefix": "sk02_addAOAIChat",
        "body": [
            "builder.Services.AddSingleton<IChatCompletionService>(sp =>",
            "{",
            "    // add Azure OpenAI Chat Completion service",
            "    var config = builder.Configuration;",
            "    var chatDeploymentName = config[\"AZURE_OPENAI_MODEL\"];",
            "    var endpoint = config[\"AZURE_OPENAI_ENDPOINT\"];",
            "    var apiKey = config[\"AZURE_OPENAI_APIKEY\"];",
            "",
            "    return new AzureOpenAIChatCompletionService(chatDeploymentName, endpoint, apiKey);",
            "});",
            ""
        ],
        "description": "add AOAI chat to aspnet program file"
    },
    "sk03_addChatHistory": {
        "prefix": "sk03_addChatHistory",
        "body": [
            "builder.Services.AddSingleton(sp => ",
            "{",
            "    return new ChatHistory();",
            "});"
        ],
        "description": "add chat history to aspnet program file"
    },
    "sk04_chatcontroller_constructor": {
        "prefix": "sk04_chatcontroller_constructor",
        "body": [
            "    public IChatCompletionService _chatCompletionService;",
            "",
            "    public ChatController(ILogger<ChatController> logger, ChatHistory chatHistory, IChatCompletionService chatCompletionService)",
            "    {",
            "        _logger = logger;",
            "        _chatHistory = chatHistory;",
            "        _chatCompletionService = chatCompletionService;",
            "    }",
            ""
        ],
        "description": "add chat controller constructor including chat history and chat completion service"
    },
    "sk05_chatresponse": {
        "prefix": "sk05_AOAIchatresponse",
        "body": [
            "",
            "var result = await _chatCompletionService.GetChatMessageContentsAsync(_chatHistory);",
            "stopwatch.Stop();",
            "",
            "var response = new Response",
            "{",
            "  Author = \"Azure OpenAI\", ",
            "  QuestionResponse = result[^1].Content,",
            "  ElapsedTime = stopwatch.Elapsed",
            "};",
            ""
        ],
        "description": "process the chat response from the AOAI Chat Completion service"
    },
    "sk06_analyzeimage": {
        "prefix": "sk06_analyzeimage",
        "body": [
            "// validate if question.ImageUrl is a valid url",
            "if (!string.IsNullOrEmpty(question.ImageUrl) && Uri.IsWellFormedUriString(question.ImageUrl, UriKind.Absolute))",
            "{",
            "    var collectionItems = new ChatMessageContentItemCollection",
            "    {",
            "        new TextContent(question.UserQuestion),",
            "        new ImageContent(new Uri(question.ImageUrl))",
            "    };",
            "    _chatHistory.AddUserMessage(collectionItems);",
            "}",
            "else",
            "{",
            "    _chatHistory.AddUserMessage(question.UserQuestion);",
            "}"
        ],
        "description": "process the question and the image url using the chat completion service"
    },
    "sk07_addONNXProjReferences": {
        "prefix": "sk07_addONNXProjReferences",
        "body": [
            "<!-- Local ONNX Models References -->",
            "<PackageReference Include=\"feiyun0112.SemanticKernel.Connectors.OnnxRuntimeGenAI.CPU\" Version=\"1.0.0\" />",
            "<PackageReference Include=\"Microsoft.ML.OnnxRuntime\" Version=\"1.18.0\" />",
            "<PackageReference Include=\"Microsoft.ML.OnnxRuntimeGenAI\" Version=\"0.3.0-rc2\" />",
            "<PackageReference Include=\"Microsoft.ML.OnnxRuntimeGenAI.Cuda\" Version=\"0.3.0-rc2\" />"
        ],
        "description": "add ONNX project references to the csproj file"
    },
    "sk08_addlocalONNXModel": {
        "prefix": "sk08_addlocalONNXModel",
        "body": [
            "// add local Phi-3 model using ONXX",
            "var modelPath = @\"D:\\phi3\\models\\Phi-3-mini-4k-instruct-onnx\\cpu_and_mobile\\cpu-int4-rtn-block-32\";",
            "builder.Services.AddOnnxRuntimeGenAIChatCompletion(modelPath: modelPath);"
        ],
        "description": "add local onnx model to the aspnet program file"
    },
    "sk09_addOllamaModelChat": {
        "prefix": "sk09_addOllamaModelChat",
        "body": [
            "builder.Services.AddSingleton<IChatCompletionService>(sp =>",
            "{",
            "    // add Phi-3 model from a ollama server",
            "    var model = \"phi3\";",
            "    var endpoint = \"http://cpc-bruno-83lkq-docker-desktop:11434\";",
            "    var apiKey = \"apiKey\";",
            "",
            "    return new OpenAIChatCompletionService(model, new Uri(endpoint), apiKey);",
            "});"
        ],
        "description": "add a new chat service that uses a remote ollama server"
    },
    "sk20_addSKMemory": {
        "prefix": "sk20_addSKMemoryToProgram",
        "body": [
            "// add memory storage using Semantic Kernel",
            "builder.Services.AddSingleton<ISemanticTextMemory>(sp =>",
            "{",
            "    var config = builder.Configuration;",
            "    var ada002 = config[\"AZURE_OPENAI_ADA02\"];",
            "    var endpoint = config[\"AZURE_OPENAI_ENDPOINT\"];",
            "    var apiKey = config[\"AZURE_OPENAI_APIKEY\"];",
            "",
            "    var memoryBuilder = new MemoryBuilder();",
            "    memoryBuilder.WithAzureOpenAITextEmbeddingGeneration(ada002, endpoint, apiKey);",
            "    memoryBuilder.WithMemoryStore(new VolatileMemoryStore());",
            "",
            "    ISemanticTextMemory memory = memoryBuilder.Build();",
            "    return memory;",
            "});"
        ],
        "description": "add memory to the builder services"
    },
    "sk21_controllerCtorWithMemory": {
        "prefix": "sk21_controllerCtorWithMemory",
        "body": [
            "public ISemanticTextMemory _memory;",
            "",
            "public ChatController(ILogger<ChatController> logger, ChatHistory chatHistory, IChatCompletionService chatCompletionService, ISemanticTextMemory semanticMemory)",
            "{",
            "_logger = logger;",
            "_chatHistory = chatHistory;",
            "_chatCompletionService = chatCompletionService;",
            "_memory = semanticMemory;",
            "}"
        ],
        "description": "add memory to the chat controller constructor"
    },
    "sk22_ControllerChatWithMemory": {
        "prefix": "sk22_ControllerChatWithMemory",
        "body": [
            "// POST api/<ChatController>",
            "[HttpPost]",
            "public async Task<Response> Post(Question question)",
            "{",
            "    _logger.LogInformation($\"Input question: {question}\");",
            "",
            "    var response = new Response();",
            "",
            "    // complete chat history",
            "    _chatHistory.AddUserMessage(question.UserQuestion);",
            "",
            "    // get response",
            "    var stopwatch = new Stopwatch();",
            "    stopwatch.Start();",
            "",
            "    var result = await SearchResultInMemory(question);",
            "    if (string.IsNullOrEmpty(result))",
            "    {",
            "        response.Author = \"Azure GPT-4o\";",
            "        var resultResponse = await _chatCompletionService.GetChatMessageContentsAsync(_chatHistory);",
            "        result = resultResponse[^1].Content;",
            "        await AddItemToMemory(question, result);",
            "        response.FromCache = false;",
            "    }",
            "    else",
            "    {",
            "        response.Author = \"Azure GPT-4o - Cache\";",
            "        response.FromCache = true;",
            "    }",
            "",
            "    response.QuestionResponse = result;",
            "",
            "    // calculate elapsed time",
            "    stopwatch.Stop();",
            "    response.ElapsedTime = stopwatch.Elapsed;",
            "",
            "    _logger.LogInformation($\"Response: {response}\");",
            "    return response;",
            "}",
            "",
            "async Task AddItemToMemory(Question question, string questionAnswer)",
            "{",
            "    int chunkSize = 6000;",
            "    List<string> chunks = new List<string>();",
            "    for (int i = 0; i < question.UserQuestion.Length; i += chunkSize)",
            "    {",
            "        string chunk = question.UserQuestion.Substring(i, Math.Min(chunkSize, question.UserQuestion.Length - i));",
            "        string key = question.UserQuestion + \"-\" + i;",
            "        await _memory.SaveInformationAsync(",
            "            collection: GetMemoryCollectionName(question),",
            "            text: chunk,",
            "            id: key,",
            "            description: questionAnswer);",
            "",
            "        _logger.LogInformation($\"Saved chunk: {key} - {chunk}\");",
            "    }",
            "}",
            "",
            "async Task<string> SearchResultInMemory(Question question)",
            "{",
            "    var returnValue = string.Empty;",
            "",
            "    // search in memory",
            "    var response = await _memory.SearchAsync(",
            "        GetMemoryCollectionName(question),",
            "        question.UserQuestion,",
            "        withEmbeddings: true,",
            "        limit: 1).FirstOrDefaultAsync();",
            "    if (response != null)",
            "    {",
            "        _logger.LogInformation($\"{question.UserQuestion} >> ID: {response?.Metadata.Id} - Description: {response?.Metadata.Description} - Relevance: {response.Relevance} - Is Reference: {response?.Metadata.IsReference}\");",
            "        if (response.Relevance > 0.8)",
            "        {",
            "            returnValue = response?.Metadata.Description;",
            "        }",
            "    }",
            "    return returnValue;",
            "}",
            "",
            "string GetMemoryCollectionName(Question question)",
            "{",
            "    return $\"user-{question.UserName}-chat\";",
            "}"
        ],
        "description": "sk22_ControllerChatWithMemory"
    }
}
{
    "sk01_imports": {
        "prefix": "sk01_imports",
        "body": [
            "#pragma warning disable SKEXP0001",
            "#pragma warning disable SKEXP0010",
            "#pragma warning disable SKEXP0020",
            "#pragma warning disable SKEXP0027",
            "#pragma warning disable SKEXP0050",
            "",
            "using Microsoft.SemanticKernel.ChatCompletion;",
            "using Microsoft.SemanticKernel.Connectors.OpenAI;",
            ""
        ],
        "description": "add sk imports to aspnet program file"
    },
    "sk02_addAOAIChat": {
        "prefix": "sk02_addAOAIChat",
        "body": [
            "builder.Services.AddSingleton<IChatCompletionService>(sp =>",
            "{",
            "    // add Azure OpenAI Chat Completion service",
            "    var config = builder.Configuration;",
            "    var chatDeploymentName = config[\"AZURE_OPENAI_MODEL\"];",
            "    var endpoint = config[\"AZURE_OPENAI_ENDPOINT\"];",
            "    var apiKey = config[\"AZURE_OPENAI_APIKEY\"];",
            "    // set author",
            "    config[\"author\"]= \"Azure OpenAI - GPT-4o\";",
            "",
            "    return new AzureOpenAIChatCompletionService(chatDeploymentName, endpoint, apiKey);",
            "});"
        ],
        "description": "add Azure OpenAI Chat Completion service to aspnet program file"
    },
    "sk10_chatcontroller_constructor": {
        "prefix": "sk10_chatcontroller_constructor",
        "body": [
            "public ChatController(ILogger<ChatController> logger, IConfiguration config, ChatHistory chatHistory, IChatCompletionService chatCompletionService)",
            "{",
            "    _logger = logger;",
            "    _config = config;",
            "    _chatHistory = chatHistory;",
            "    _chatCompletionService = chatCompletionService;",
            "}"
        ],
        "description": "sk10_chatcontroller_constructor"
    },
    "sk11_chatAOAIresponse": {
        "prefix": "sk11_chatAOAIresponse",
        "body": [
            "// POST api/<ChatController>",
            "[HttpPost]",
            "public async Task<Response> Post(Question question)",
            "{",
            "    _logger.LogInformation($\"Input question: {question}\");",
            "",
            "    var response = new Response",
            "    {",
            "        Author = _config[\"Author\"]",
            "    };",
            "",
            "    // complete chat history",
            "    _chatHistory.AddUserMessage(question.UserQuestion);",
            "",
            "    // get response",
            "    var stopwatch = new Stopwatch();",
            "    stopwatch.Start();",
            "    var result = await _chatCompletionService.GetChatMessageContentsAsync(_chatHistory);",
            "    stopwatch.Stop();",
            "",
            "    response.QuestionResponse = result[^1].Content;",
            "    response.ElapsedTime = stopwatch.Elapsed;",
            "",
            "    // return response",
            "    _logger.LogInformation($\"Response: {response}\");",
            "    return response;",
            "}"
        ],
        "description": "Post API that use AOAI to answer a question"
    },
    "sk12_analyzeimage": {
        "prefix": "sk12_analyzeimage",
        "body": [
            "// validate if question.ImageUrl is a valid url",
            "if (question.IsImage)",
            "{",
            "    var collectionItems = new ChatMessageContentItemCollection",
            "    {",
            "        new TextContent(question.UserQuestion),",
            "        new ImageContent(question.FileBytes, question.ImageMimeType)",
            "    };",
            "    _chatHistory.AddUserMessage(collectionItems);",
            "}",
            "else",
            "{",
            "    _chatHistory.AddUserMessage(question.UserQuestion);",
            "}"
        ],
        "description": "analyze image and add to chat history"
    },
    "sk20_addlocalONNXModel": {
        "prefix": "sk20_addlocalONNXModel",
        "body": [
            "// add local Phi-3 model using ONXX",
            "var modelPath = @\"D:\\phi3\\models\\Phi-3-mini-4k-instruct-onnx\\cpu_and_mobile\\cpu-int4-rtn-block-32\";",
            "builder.Services.AddOnnxRuntimeGenAIChatCompletion(modelPath: modelPath);",
            "builder.Configuration[\"author\"]= \"Phi-3 mini ONNX\";"
        ],
        "description": "load a local ONNX model to chat service"
    },
    "sk21_addlocalONNXVisionModel": {
        "prefix": "sk21_addlocalONNXVisionModel",
        "body": [
            "// add local Phi-3 Vision model using ONXX",
            "var modelPath = @\"D:\\phi3\\models\\Phi-3-vision-128k-instruct-onnx-cpu\\cpu-int4-rtn-block-32-acc-level-4\";",
            "builder.Services.AddOnnxRuntimeGenAIChatCompletion(modelPath: modelPath);",
            "builder.Configuration[\"author\"]= \"Phi-3 Vision ONNX\";"
        ],
        "description": "load a local ONNX model to chat service"
    },    
    "sk09_addOllamaModelChat": {
        "prefix": "sk21_addOllamaModelChat",
        "body": [
            "builder.Services.AddSingleton<IChatCompletionService>(sp =>",
            "{",
            "    // add Phi-3 model from a ollama server",
            "    var model = \"phi3\";",
            "    var endpoint = \"http://localhost:11434\";",
            "    var apiKey = \"apiKey\";",
            "    builder.Configuration[\"author\"]= \"Phi-3 Ollama Docker\";",
            "",
            "    return new OpenAIChatCompletionService(model, new Uri(endpoint), apiKey);",
            "});"
        ],
        "description": "add a new chat service that uses a remote ollama server"
    },
    "sk20_addSKMemory": {
        "prefix": "sk30_addSKMemoryToProgram",
        "body": [
            "// add memory storage using Semantic Kernel",
            "builder.Services.AddSingleton<ISemanticTextMemory>(sp =>",
            "{",
            "    var config = builder.Configuration;",
            "    var ada002 = config[\"AZURE_OPENAI_ADA02\"];",
            "    var endpoint = config[\"AZURE_OPENAI_ENDPOINT\"];",
            "    var apiKey = config[\"AZURE_OPENAI_APIKEY\"];",
            "",
            "    var memoryBuilder = new MemoryBuilder();",
            "    memoryBuilder.WithAzureOpenAITextEmbeddingGeneration(ada002, endpoint, apiKey);",
            "    memoryBuilder.WithMemoryStore(new VolatileMemoryStore());",
            "",
            "    ISemanticTextMemory memory = memoryBuilder.Build();",
            "    return memory;",
            "});"
        ],
        "description": "add memory to the builder services"
    },
    "sk31_controllerCtorWithMemory": {
        "prefix": "sk31_controllerCtorWithMemory",
        "body": [
            "public ChatController(ILogger<ChatController> logger, IConfiguration config, ChatHistory chatHistory, IChatCompletionService chatCompletionService, ISemanticTextMemory semanticMemory)",
            "{",
            "    _logger = logger;",
            "    _config = config;",
            "    _chatHistory = chatHistory;",
            "    _chatCompletionService = chatCompletionService;",
            "    _memory = semanticMemory;",
            "}"
        ],
        "description": "sk31_controllerCtorWithMemory"
    },
    "sk32_ControllerChatWithMemory": {
        "prefix": "sk32_ControllerChatWithMemory",
        "body": [
            "// POST api/<ChatController>",
            "[HttpPost]",
            "public async Task<Response> Post(Question question)",
            "{",
            "    _logger.LogInformation($\"Input question: {question}\");",
            "",
            "    var response = new Response",
            "    {",
            "        Author = _config[\"Author\"]",
            "    };",
            "",
            "    // get response",
            "    var stopwatch = new Stopwatch();",
            "    stopwatch.Start();",
            "",
            "    var result = await SearchResultInMemory(question);",
            "    if (string.IsNullOrEmpty(result))",
            "    {",
            "        // complete chat history",
            "        _chatHistory.AddUserMessage(question.UserQuestion);",
            "",
            "        response.Author = \"Azure GPT-4o\";",
            "        var resultResponse = await _chatCompletionService.GetChatMessageContentsAsync(_chatHistory);",
            "        result = resultResponse[^1].Content;",
            "        await AddItemToMemory(question, result);",
            "        response.FromCache = false;",
            "    }",
            "    else",
            "    {",
            "        response.Author += \" [Cache]\";",
            "        response.FromCache = true;",
            "    }",
            "",
            "    response.QuestionResponse = result;",
            "",
            "    // calculate elapsed time",
            "    stopwatch.Stop();",
            "    response.ElapsedTime = stopwatch.Elapsed;",
            "",
            "    _logger.LogInformation($\"Response: {response}\");",
            "    return response;",
            "}",
            "",
            "async Task AddItemToMemory(Question question, string questionAnswer)",
            "{",
            "    int chunkSize = 6000;",
            "    List<string> chunks = new List<string>();",
            "    for (int i = 0; i < question.UserQuestion.Length; i += chunkSize)",
            "    {",
            "        string chunk = question.UserQuestion.Substring(i, Math.Min(chunkSize, question.UserQuestion.Length - i));",
            "        string key = question.UserQuestion + \"-\" + i;",
            "",
            "        // process key to only contain letters, digits, underscore (_), dash (-), or equal sign (=)",
            "        key = new string(key.Where(c => char.IsLetterOrDigit(c) || c == '_' || c == '-' || c == '=').ToArray());",
            "",
            "        await _memory.SaveInformationAsync(",
            "            collection: GetMemoryCollectionName(question),",
            "            text: chunk,",
            "            id: key,",
            "            description: questionAnswer);",
            "",
            "        _logger.LogInformation($\"Saved chunk: {key} - {chunk}\");",
            "    }",
            "}",
            "",
            "async Task<string> SearchResultInMemory(Question question)",
            "{",
            "    var returnValue = string.Empty;",
            "",
            "    var collectionName = GetMemoryCollectionName(question);",
            "",
            "    // search in memory",
            "    var response = await _memory.SearchAsync(",
            "        collectionName,",
            "        question.UserQuestion,",
            "        withEmbeddings: true,",
            "        limit: 1).FirstOrDefaultAsync();",
            "    if (response != null)",
            "    {",
            "        _logger.LogInformation($\"{question.UserQuestion} >> ID: {response?.Metadata.Id} - Description: {response?.Metadata.Description} - Relevance: {response.Relevance} - Is Reference: {response?.Metadata.IsReference}\");",
            "        if (response.Relevance > 0.9)",
            "        {",
            "            returnValue = response?.Metadata.Description;",
            "        }",
            "    }",
            "    return returnValue;",
            "}",
            "",
            "string GetMemoryCollectionName(Question question)",
            "{",
            "    return $\"user-{question.UserName}-chat\";",
            "}"
        ],
        "description": "sk32_ControllerChatWithMemory"
    },
    "sk33_addSemanticMemoryAISearch": {
        "prefix": "sk33_addSemanticMemoryAISearch",
        "body": [
            "// add memory storage using Semantic Kernel",
            "builder.Services.AddSingleton<ISemanticTextMemory>(sp =>",
            "{",
            "    var config = builder.Configuration;",
            "    var ada002 = config[\"AZURE_OPENAI_ADA02\"];",
            "    var endpoint = config[\"AZURE_OPENAI_ENDPOINT\"];",
            "    var apiKey = config[\"AZURE_OPENAI_APIKEY\"];",
            "    var aiSearchEndpoint = config[\"AZURE_AISEARCH_ENDPOINT\"];",
            "    var aiSearchApiKey = config[\"AZURE_AISEARCH_APIKEY\"];",
            "",
            "    var memoryBuilder = new MemoryBuilder();",
            "    memoryBuilder.WithAzureOpenAITextEmbeddingGeneration(ada002, endpoint, apiKey);",
            "    memoryBuilder.WithMemoryStore(new AzureAISearchMemoryStore(aiSearchEndpoint, aiSearchApiKey));",
            "    ",
            "    var memory = memoryBuilder.Build();",
            "    return memory;",
            "});"
        ],
        "description": "add semantic memory with Azure AI Search Memory Store"
    },
    "sk40_RAGControllerConstructor": {
        "prefix": "sk40_RAGControllerConstructor",
        "body": [
            "",
            "private string _aiSearchEndpoint;",
            "private string _aiSearchApiKey;",
            "private string _aiSearchIndexName;",
            "",
            "public ChatController(ILogger<ChatController> logger, IConfiguration config, ChatHistory chatHistory, IChatCompletionService chatCompletionService)",
            "{",
            "    _logger = logger;",
            "    _config = config;",            
            "    _chatHistory = chatHistory;",
            "    _chatCompletionService = chatCompletionService;",
            "",
            "    _aiSearchEndpoint = _config[\"AZURE_AISEARCH_ENDPOINT\"];",
            "    _aiSearchApiKey = _config[\"AZURE_AISEARCH_APIKEY\"];",
            "    _aiSearchIndexName = _config[\"AZURE_AISEARCH_INDEXNAME\"];",
            "}"
        ],
        "description": "sk40_RAGControllerConstructor"
    },
    "sk41_RAGControllerAPIPost": {
        "prefix": "sk41_RAGControllerAPIPost",
        "body": [
            "// POST api/<ChatController>",
            "[HttpPost]",
            "public async Task<Response> Post(Question question)",
            "{",
            "    _logger.LogInformation($\"Input question: {question}\");",
            "",
            "    var response = new Response",
            "    {",
            "        Author = _config[\"Author\"]",
            "    };",
            "",
            "    // validate if question.ImageUrl is a valid url",
            "    if (question.IsImage)",
            "    {",
            "        var collectionItems = new ChatMessageContentItemCollection",
            "    {",
            "        new TextContent(question.UserQuestion),",
            "        new ImageContent(question.FileBytes, question.ImageMimeType)",
            "        };",
            "        _chatHistory.AddUserMessage(collectionItems);",
            "    }",
            "    else",
            "    {",
            "        _chatHistory.AddUserMessage(question.UserQuestion);",
            "    }",
            "",
            "    // get response",
            "    var stopwatch = new Stopwatch();",
            "    stopwatch.Start();",
            "",
            "    var azureSearchExtensionConfiguration = new AzureSearchChatExtensionConfiguration",
            "    {",
            "        SearchEndpoint = new Uri(_aiSearchEndpoint),",
            "        Authentication = new OnYourDataApiKeyAuthenticationOptions(_aiSearchApiKey),",
            "        IndexName = _aiSearchIndexName",
            "    };",
            "",
            "    var chatExtensionsOptions = new AzureChatExtensionsOptions { Extensions = { azureSearchExtensionConfiguration } };",
            "    var executionSettings = new OpenAIPromptExecutionSettings { AzureChatExtensionsOptions = chatExtensionsOptions };",
            "",
            "    // run the prompt",
            "    var result = await _chatCompletionService.GetChatMessageContentsAsync(_chatHistory, executionSettings);",
            "",
            "    if (result.FirstOrDefault().InnerContent is ChatResponseMessage)",
            "    {",
            "        response.Citations = new List<Citation>();",
            "        var ic = result.FirstOrDefault().InnerContent as ChatResponseMessage;",
            "        var aec = ic.AzureExtensionsContext;",
            "        var citations = aec.Citations;",
            "        int count = 0;",
            "        foreach (var citation in citations)",
            "        {",
            "            if (count >= 3) break;",
            "            count++;",
            "            var newC = new Citation();",
            "            newC.Title = citation.Title;",
            "            newC.URL = citation.Url;",
            "            newC.FilePath = citation.Filepath;",
            "            newC.Content = citation.Content;",
            "            response.Citations.Add(newC);",
            "        }",
            "    }",
            "",
            "    stopwatch.Stop();",
            "",
            "    response.QuestionResponse = result[^1].Content;",
            "    response.ElapsedTime = stopwatch.Elapsed;",
            "",
            "    // return response",
            "    _logger.LogInformation($\"Response: {response}\");",
            "    return response;",
            "}"
        ],
        "description": "add search including an index of Azure AI Search"
    },
    "sk50_AddOTLPEndpoint": {
        "prefix": "sk50_AddOTLPEndpoint",
        "body": [
            "builder.Logging.AddOpenTelemetry(logging =>",
            "{",
            "    var config = builder.Configuration;",
            "    var otlpEndPoint = config[\"OTLP_ENDPOINT\"];",
            "    logging.AddOtlpExporter(configure => configure.Endpoint = new Uri(otlpEndPoint));",
            "    logging.IncludeFormattedMessage = true;",
            "    logging.IncludeScopes = true;",
            "});"
        ],
        "description": "sk50_AddOTLPEndpoint"
    }
}
{
    "sk01_imports": {
        "prefix": "sk01_imports",
        "body": [
            "#pragma warning disable SKEXP0001",
            "#pragma warning disable SKEXP0010",
            "#pragma warning disable SKEXP0020",
            "#pragma warning disable SKEXP0027",
            "#pragma warning disable SKEXP0050",
            "",
            "using Microsoft.SemanticKernel.ChatCompletion;",
            "using Microsoft.SemanticKernel.Connectors.OpenAI;",
            ""
        ],
        "description": "add sk imports to aspnet program file"
    },
    "sk02_addAOAIChat": {
        "prefix": "sk02_addAOAIChat",
        "body": [
            "builder.Services.AddSingleton<IChatCompletionService>(sp =>",
            "{",
            "    // add Azure OpenAI Chat Completion service",
            "    var config = builder.Configuration;",
            "    var chatDeploymentName = config[\"AZURE_OPENAI_MODEL\"];",
            "    var endpoint = config[\"AZURE_OPENAI_ENDPOINT\"];",
            "    var apiKey = config[\"AZURE_OPENAI_APIKEY\"];",
            "",
            "    return new AzureOpenAIChatCompletionService(chatDeploymentName, endpoint, apiKey);",
            "});",
            ""
        ],
        "description": "add AOAI chat to aspnet program file"
    },
    "sk03_addChatHistory": {
        "prefix": "sk03_addChatHistory",
        "body": [
            "builder.Services.AddSingleton(sp => ",
            "{",
            "    return new ChatHistory();",
            "});"
        ],
        "description": "add chat history to aspnet program file"
    },
    "sk04_chatcontroller_constructor": {
        "prefix": "sk04_chatcontroller_constructor",
        "body": [
            "    private ChatHistory _chatHistory;",
            "    public IChatCompletionService _chatCompletionService;",
            "",
            "    public ChatController(ILogger<ChatController> logger, ChatHistory chatHistory, IChatCompletionService chatCompletionService)",
            "    {",
            "        _logger = logger;",
            "        _chatHistory = chatHistory;",
            "        _chatCompletionService = chatCompletionService;",
            "    }",
            ""
        ],
        "description": "add chat controller constructor including chat history and chat completion service"
    },
    "sk05_chatresponse": {
        "prefix": "sk05_chatresponse",
        "body": [
            "// complete history",
            "_chatHistory.AddUserMessage(question.UserQuestion);",
            "",
            "// get response",
            "var result = await _chatCompletionService.GetChatMessageContentsAsync(_chatHistory);",
            "var response = new Response",
            "{",
            "  Author = \"Azure OpenAI\", ",
            "  QuestionResponse = result[^1].Content",
            "};",
            ""
        ],
        "description": "process the chat response from the chat completion service"
    },
    "sk06_analyzeimage": {
        "prefix": "sk06_analyzeimage",
        "body": [
            "// validate if question.ImageUrl is a valid url",
            "if (!string.IsNullOrEmpty(question.ImageUrl) && Uri.IsWellFormedUriString(question.ImageUrl, UriKind.Absolute))",
            "{",
            "    var collectionItems = new ChatMessageContentItemCollection",
            "    {",
            "        new TextContent(question.UserQuestion),",
            "        new ImageContent(new Uri(question.ImageUrl))",
            "    };",
            "    _chatHistory.AddUserMessage(collectionItems);",
            "}",
            "else",
            "{",
            "    _chatHistory.AddUserMessage(question.UserQuestion);",
            "}"
        ],
        "description": "process the question and the image url using the chat completion service"
    },
    "sk07_addONNXProjReferences": {
        "prefix": "sk07_addONNXProjReferences",
        "body": [
            "<!-- Local ONNX Models References -->",
            "<PackageReference Include=\"feiyun0112.SemanticKernel.Connectors.OnnxRuntimeGenAI.CPU\" Version=\"1.0.0\" />",
            "<PackageReference Include=\"Microsoft.ML.OnnxRuntime\" Version=\"1.18.0\" />",
            "<PackageReference Include=\"Microsoft.ML.OnnxRuntimeGenAI\" Version=\"0.3.0-rc2\" />",
            "<PackageReference Include=\"Microsoft.ML.OnnxRuntimeGenAI.Cuda\" Version=\"0.3.0-rc2\" />"
        ],
        "description": "add ONNX project references to the csproj file"
    },
    "sk08_addlocalONNXModel": {
        "prefix": "sk08_addlocalONNXModel",
        "body": [
            "// add local Phi-3 model using ONXX",
            "var modelPath = @\"D:\\phi3\\models\\Phi-3-mini-4k-instruct-onnx\\cpu_and_mobile\\cpu-int4-rtn-block-32\";",
            "builder.Services.AddOnnxRuntimeGenAIChatCompletion(modelPath: modelPath);"
        ],
        "description": "add local onnx model to the aspnet program file"
    },
    "sk09_addOllamaModelChat": {
        "prefix": "sk09_addOllamaModelChat",
        "body": [
            "builder.Services.AddSingleton<IChatCompletionService>(sp =>",
            "{",
            "    // add Phi-3 model from a ollama server",
            "    var model = \"phi3\";",
            "    var endpoint = \"http://cpc-bruno-83lkq-docker-desktop:11434\";",
            "    var apiKey = \"apiKey\";",
            "",
            "    return new OpenAIChatCompletionService(model, new Uri(endpoint), apiKey);",
            "});"
        ],
        "description": "add a new chat service that uses a remote ollama server"
    }
}